--- 
title: "Elementary Statistical Modeling for Applied Biostatistics"
author: "Jeffrey A. Walker"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: 
description: "A first course in statistical modeling for biology students"
---

```{r bookdown, include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

```{r libraries, echo=FALSE}
base_path <- "data"
library(knitr)
library(ggplot2)
library(readxl)
library(cowplot)
library(data.table)
library(lme4)
library(HarrellPlot)
library(date)
```

# Statistical Modeling

*More cynically, one could also well ask "Why has medicine not adopted frequentist inference, even though everyone presents P-values and hypothesis tests?" My answer is: Because frequentist inference, like Bayesian inference, is not taught. Instead everyone gets taught a misleading pseudo-frequentism: a set of rituals and misinterpretations caricaturing frequentist inference, leading to all kinds of misunderstandings.* -- Sander Greenland

We use statistics to learn from data with uncertainty. Traditional introductory textbooks in biostatistics implicitly or explicitly train students and researchers to "discover by p-value" using hypothesis tests (appendix xxx). Over the course of many chapters, the student is trained to use something like a dichotomous key to choose the correct "test" for the data at hand, compute a test statistic for their data, compute a $p$-value based on the test statistic, and compares the *p*-value to 0.05. Textbooks typically give very little guidance about what can be concluded if $p < 0.05$ or if $p > 0.05$, but many researchers conclude they have "discovered" something if $p < 0.05$ but found "no effect" if $p > 0.05$.

Researchers learn almost nothing useful from a hypothesis test. If we are investigating the effects of an increasingly acidified ocean on coral growth, $p=0.002$ may be evidence that pH affects growth, but, from everything we know about pH and cell biology, it would be absurd to conclude from any data that ocean acidification does not affect growth. Instead, we want to know the magnitude of the effect and our uncertainty in estimating this magnitude. We can use this magnitude and uncertainty to make predictions about the future of coral reefs, under different scenarios of ocean acidification. We can use the estimated effects and uncertainty to model the consquences of the effects of acidification on coral growth on fish production or carbon cycling.

The "discovery by p-value" strategy, or Null-Hypothesis Significance Testing (NHST), has been criticized by statisticians for many, many decades. Nevertheless, introductory biostatistics textbooks written by both biologists and statisticians continue to organize textbooks around a collection of hypothesis tests, with little emphasis on estimation and uncertainty.

## Statistical modeling with linear models
This textbook is an introduction to the analysis of biological data using a statistical modeling approach. As an introduction, the focus will be linear models and extensions of the linear models including linear mixed models and generalized linear models. Here, I refer to all of these as "linear models" because all are a function of a linear predictor. Linear models are the engine behind many hypothesis tests but the emphasis in statistical modeling is estimation and uncertainty instead of test statistics and $p$-values. A modeling view of statistics is also more coherent than a dichotomous key strategy.

> **Box**
> 
> linear mixed models are also known as multilevel models and hierarchical models. Generalized linear models (GLMs) are frequently called non-linear models. While it is true that the response ($Y$) is usually a non-linear function of the $X$ in a GLM, the expected values of $Y$ are a non-linear transformation of a linear predictor function like that in equation \@ref(eq:lm). A common phrase is that GLMs are "linear in the parameters."

```{r line, echo=FALSE, fig.cap="A line vs. a linear model. (A) the line $y=-3.48X + 105.7 is drawn. (B) A linear model fit to the data. The model coefficients are numerically equal to the slope and intercept of the line in A."}
set.seed(1)
b0 <- 105.8
b1 <- -3.5
sigma <- 1.0
x <- rep(10:15, each=3)
n <- length(x)
y <- b0 + b1*x + rnorm(n)*sigma
b_vec <- coefficients(lm(y~x))
b <- b_vec[1]
m <- b_vec[2]

dt <- data.table(X=x, Y=y)
gg1 <- ggplot(data=dt, aes(x=X, y=Y)) +
  geom_smooth(method='lm', se=FALSE) +
  theme_minimal()

gg2 <- gg1 +
  geom_point()

gg <- plot_grid(gg1, gg2, labels = c("A", "B"))
gg

```

All students are familiar with the idea of a linear model from learning the equation of a line, which is

\begin{equation}
Y = mX + b
(\#eq:line)
\end{equation}

where $m$ is the slope of the line and $b$ is the $Y$-intercept. It is useful to think of equation \@ref(eq:line) as a function that maps values of $X$ to values of $Y$. Using this function, if we input some value of $X$, we always get the same value of Y as the output.

```{r lineCode, echo=FALSE}
line2 <- function(x){
  return(m*x+b)
}
```

A linear model is a function, like that in equation \@ref(eq:line), that is fit to a set of data, often to model a process that generated the data or something like the data. The line in Figure \@ref(fig:line)A is just that, a line, but the line in Figure \@ref(fig:line)B is a model of the data in Figure \@ref(fig:line)B. The basic structure of a linear model is

\begin{equation}
Y = \beta_0 + \beta_1 X + \varepsilon
(\#eq:lm)
\end{equation}

A linear model has two parts: the "model" ($Y = \beta_0 + \beta_1 X$) and the "error"  ($\varepsilon$). The model part looks like the equation for a line except that I've used $\beta_0$ for the intercept and $\beta_1$ for the slope and I've put the intercept term first. This re-labeling and re-arrangement make the notation for a linear model more flexible for more complicated linear models. For example $Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \varepsilon$ is a model where $Y$ is a function of two $X$ variables.

As with the equation for a line, the model part of a linear model is a function that maps a value of $X$ to a specific value of $Y$. This mapped value is the **expected value** given a specific input value of $X$. The error part of a linear model is a random variable that adds some random value to this expected value. Nothing about the model part of a linear model can predict its value. 

The inputs to a linear model (the $X$ variables) have many names including "independent variables," "predictor variables,", "explanatory variables," "treatment variables," and "covariates". The output of a linear model (the $Y$ variable or variables if the model is multivariate) is the "dependent variable," "response," or "outcome." The $\beta$ in the linear model are model **parameters** There can be additional parameters in more sophisticated models. The coefficients of the $X$ in a linear model ($\beta_1$ in model \@ref(eq:lm)) are often called "the effects" (so $\beta_1$ is the effect of $X_1$).

Although a linear model is a model of a data-generating process, linear models are not typically used to actually generate any data. Instead, when we use a linear model to understand something about a real dataset, we think of our data as one realization of a process that generates data like ours. A linear model is a model of that process. That said, it is incredibly useful to use linear models to create fake datasets for at least two reasons: to probe our understanding of statistical modeling generally and, more specifically, to check that a model actually creates data like that in the real dataset that we are analyzing.

### Linear models are used for prediction, explanation, and description

Researchers typically use linear models to understand relationships between one or more $Y$ variables and one or more $X$ variables. These relationships include

1. Descriptive modeling. Sometimes a researcher merely wants to describe the relationship between $Y$ and a set of $X$ variables, perhaps to discover patterns. For example, the arrival of a spring migrant bird ($Y$) as a function of sex ($X_1$) and age ($X_2$) might show that males and younger individuals arrive earlier. Importantly, if another $X$ variable is added to the model (or one dropped), the coefficients, and therefore, the precise description, will change. That is, the interpretation of a coefficient as a descriptor is *conditional* on the other covariates ($X$ variables) in the model. In a descriptive model, there is no implication of causal effects and the goal is not prediction. Nevertheless, it is very hard for humans to discuss a descriptive model without using causal language, which probably means that it is hard for us to think of these models as *mere description*. Like natural history, descriptive models are useful as patterns in want of an explanation, using more explicit causal models including experiments.

2. Predictive modeling. Predictive modeling is very common in applied research. For example, fisheries researchers might model the relationship between population density and habitat variables to predict which subset of ponds in a region are most suitable for brook trout (*Salvelinus fontinalis*) reintroduction. The goal is to build a model with minimal prediction error, which is the error between predicted and actual values for a future sample. In predictive modeling, the $X$ ("predictor") variables are largely instrumental -- how these are related to $Y$ is not a goal of the modeling, although sometimes an investigator may be interested in the relative importance among the $X$ for predicting $Y$ (for example, collecting the data may be time consuming, or expensive, or enviromentally destructive, so know which subset of $X$ are most important for predicting $Y$ is a useful strategy).

3. Explanatory (causal) modeling. Very often, researchers are explicitly interested in *how* the $X$ variables are causally related to $Y$. The fisheries researchers that want to reintroduce trout may want to develop and manage a set of ponds to maintain healthy trout populations. This active management requires intervention to change habitat traits in a direction, and with a magnitude, to cause the desired response. This model is predictive -- a specific change in $X$ predicts a specific response in $Y$ -- because the coefficients of the model provide knowledge on how the system functions -- how changes in the inputs *cause* change in the output. Causal interpretation of model coefficients requires a set of strong assumptions about the $X$ variables in the model.

Biologists are often not very explicit about which of these is the goal of the modeling and use a combination of descriptive, predictive, and causal language to describe and discuss results. By contrast, researchers in economics and other social sciences, as well as epidemiology and medicine more generally, are usually very explicit if their model is descriptive, predictive, or causal.

## Model fitting

In order to use a linear model to describe, predict, or explain, we need to fit a model to data. Instead of using an abtract model like that in model \@ref(eq:lm), I will introduce model fitting using data from Dryad Data Repository.

### A linear model with a single, continous $X$

The data are from @Dantzer_xxx, who showed that North American red squirrel (*Tamiasciurus hudsonicus*) mothers from Yukon, Alaska produce faster growing pups in years with increased squirrel density. Remarkably, they even showed that perceived (but not actual) density results in faster growing pups. To begin to investigate how pregnant mothers control the future growth rate of pups, the researchers measured the relationship between local squirrel density and the amount of fecal cortisol metabolites from pregnant mothers. Cortisol is a hormone that is secreted as part of stress response. The researchers were interested in cortisol because it had previously been shownt that, in mammals, blood cortisol levels in pregnant mothers have numerous effects on offspring long past birth. If increased squirrel density causes increased blood cortisol levels then we would expect to find a positive relationship between $Density$ and  

```{r squirrel, echo=FALSE, warning=FALSE, fig.cap="A scatterplot of Fecal cortisol matabolites and squirrel density."}
# When using this data, please cite the original publication:
# 
# Dantzer B, Newman AEM, Boonstra R, Palme R, Boutin S, Humphries MM, McAdam AG (2013) Density triggers maternal hormones that increase adaptive offspring growth in a wild mammal. Science, online in advance of print. https://doi.org/10.1126/science.1235765
# 
# Additionally, please cite the Dryad data package:
# 
# Dantzer B, Newman AEM, Boonstra R, Palme R, Boutin S, Humphries MM, McAdam AG (2013) Data from: Density triggers maternal hormones that increase adaptive offspring growth in a wild mammal. Dryad Digital Repository. https://doi.org/10.5061/dryad.b3h4q

# data for Fig 3A/Table S4
fn <- "FCM data dryad.csv"
data_path <- "data/"
file_path <- paste(data_path, fn, sep="")
fcm <- fread(file_path, stringsAsFactors = TRUE)
# change names of variables
fcm[, Density:=Raw.Squirrel.Density]
fcm[, FCM:=FCM.ng.g.dry]
gg <- ggplot(data=fcm, aes(x=Density, y=FCM)) +
  geom_point() +
  geom_smooth(method='lm') +
  theme_minimal() +
  NULL
gg

```

Figure \@ref(fig:squirrel) is a **scatterplot** of the data with the amount of cortisol metabolites in the feces on the $Y$ axis and local squirrel density on the $X$ axis. The line through the data is a graphical representation of a linear model fit to the data and the gray cloud around the line is a graphical representation of the uncertainty in the model. The researchers wanted to model the "effect" of squirrel density on the amount of cortisol metabolites in the feces of the pregnant mothers. Graphically, this effect is the slope of the line in Figure \@ref(fig:squirrel).

The model is

\begin{equation}
\textrm{E}[FCM|Density] = \beta_0 + \beta_1 Density
(\#eq:regression)
\end{equation}

In words, model \@ref(eq:regression) reads "the expected value of $FCM$ conditional on density is beta-knot plus beta-one times density". An **expected value** is a long run average -- if we were to sample lots and lots of red squirrel populations with $Density=x$ (where $x$ is a specific value), we'd expect the average $FCM$ across these samples to be $\beta_0 + \beta_1 x$.

In model \@ref(eq:regression), there is a single $X$ variable ($FCM$). While the $X$ variables are often called the "dependent" variables, in this model $FCM$ does not "depend" on the independent variable $Density$ in any causal sense -- meaning if I were to intervene and set $Density$ to some value $x$, I would expect $FCM$ to equal $\beta_0 + \beta_1 x$. Rather, $FCM$ only "depends" on $Density$ in a probablistic sense -- if $Density = x$ then the most probable value of $FCM$ is $\beta_0 + \beta_1 x$. With some strong assumptions model \@ref(eq:regression) can be turned into a model of causal dependency, which is the focus of chapter xxx.

$\beta_0$ and $\beta_1$ are the **parameters** of model \@ref(eq:regression). Specifically $\beta_0$ is the model **intercept** and $\beta_1$ is the modeled **effect** of $Density$. Again, the effect ($\beta_1$) has a probabilistic, and not causal, interpretation. This interpretation is

\begin{equation}
\beta_1 = \textrm{E}[FCM|Density=x+1] - \textrm{E}[FCM|Density=x] 
(\#eq:beta1)
\end{equation}

Or, in words, "beta-1 is the expected value of FCM when density equals x + 1 minus the expected value of FCM when the density equals x." $\beta_1$ is simply the difference in expected values given a one unit difference in $Density$.

#### Using a linear model to estimate effects

The goal of the statistical model here is to estimate $\beta_1$ -- the probabalistic effect of $Density$ on $FCM$. This estimate, and a measure of the uncertainty of this estimate, are in the table of coefficients of the fit model

```{r squirrel_lm, echo=FALSE}

# table S4
fit_fcm <- lm(FCM ~ Density, data=fcm)
coefficients(summary(fit_fcm))
```

where the entries in the column "Estimate" are estimates of the parameters $\beta_0$ and $\beta_1$ in model \@ref(eq:regression). The entries in the column "Std. Error" are the standard errors (SE) of the estimates, which are measures of the uncertainty of the estimates.

The parameter estimates in the table above are the coefficients of the fitted model

\begin{equation}
FCM_i = b_0 + b_1 Density_i + e_i
(\#eq:fcmi)
\end{equation}

where the subscript *i* refers to the *i*th individual. The coefficients $b_0$ and $b_1$ are the y-intercept and the slope of the line in Figure \@ref(fig:squirrel). The coefficient for $Density$ ($b_1$) is `r round(coef(fit_fcm)["Density"],1)`, and (given the definition of the parameter $\beta_1$ in equation \@ref(eq:beta1)) we expect squirrel mothers with a local density of 2 squirrels within a 150 m radius of her midden to average 671.1 more units of FCM (ng of fecal cortical metabolites per gram dry food) than mother squirrels with a local density of only 1 squirrel within a 150 m radius of her midden. Remember that this coefficient is estimating a probabilistic parameter. Consequently, the coefficient $b_1$ is simply a descriptor of a pattern of relationship between local density and fecal cortisol metabolites - no causal effect is implied. With the strong assumptions explained in chapter xxx, however, $b_1$ can estimate a causal effect.

#### Using a linear model for prediction

Model \@ref(eq:fcmi) gives the measured value of *FCM* for each squirrel. The equation includes the modeled part ($b_0 + b_1 Density_i$) and the **residual** from the model ($e_i$). The modeled part is the modeled or **predicted value**,

\begin{equation}
\widehat{FCM} = b_0 + b_1 Density
(\#eq:fcmhat)
\end{equation}

where $\widehat{FCM}$ is read as "FCM hat". Very often, we use the model part (equation \@ref(eq:fcmhat)) to predict unknown or future values given different modeled inputs (the $X$).

### Linear models with categorical $X$ are the same as linear models with continuous $X$

Singh et al. (xxx) studied the effect of parasite infection on the production of recombinant offspring in several lines of fruit fly *Drosophila melanogaster*. Recombinant offspring are those with allele combinations that do not occur in either parent.

```{r recombinantfly, echo=FALSE, results=FALSE}
fn <- "InfectionRecombinationForDyrad.xls"
data_path <- "data/Data from Fruit flies diversify their offspring in response to parasite infection/"
file_path <- paste(data_path, fn, sep="")
fly <- data.table(read_excel(file_path, sheet="Late"))
setnames(fly, old="Recombinant fraction", new="Recombinant_fraction")
treatment_levels <- c("Control", "Wounded", "Smarc", "Prett")
fly[, Treatment:=factor(Treatment, treatment_levels)]

sub_levels <- c("Wounded", "Smarc")
sub_fly <- fly[Treatment %in% sub_levels, ]
sub_fly[, Treatment:=factor(Treatment, sub_levels)]

fit_recombinant <- lm(Recombinant_fraction ~ Treatment, data=sub_fly)
res <- HarrellPlot(x='Treatment', y='Recombinant_fraction', data=sub_fly, y_label = "Recombinant Fraction", display.treatment='none', show.mean=TRUE)

```

```{r recombinantFlyPlot, echo=FALSE, fig.cap="Harrell plot of fly data. The bottom part of the graph shows the data while the top part shows the effect estimate and a measure of uncertainty. The specifics of the plot will be explained in Chapter xxx. Briefly, the large black dots within the boxes in the bottom part are the group mean recombinant frequencies. The black dot in the top part of the plot is the difference in these group means (the effect)."}

res$gg

```

Figure \@ref(fig:recombinantFlyPlot), shows the results of one of the experiments, specifically, the recombinant frequencies for each replicate of the **treatment levels** "Smarc" (flies who were parasitized by the bacteria *Serratia marcescens*) and "Wounded" (flies who were given a sterile wound as a control). The mean of each treatment level (or group) is shown with the large black dot within the group's scatter of individual values, and the difference in the means is shown in the top part with the black dot in the top part. The top plot also shows a measure of the uncertainty in the estimate of this difference (the thick black line).

The means of the two treatment levels (groups) are

```{r fly_means, echo=FALSE}
means <- sub_fly[, .(mean=mean(Recombinant_fraction)), by=Treatment]
diff.means <- means[Treatment=='Smarc', mean] - means[Treatment=='Wounded',mean]
means
```

The difference between the means is `r diff.means`. This is the estimate of the effect of *S. marcescens* parasitism on recombinant frequency. In general, we wouldn't report these means or this difference in means to this precision because the raw measures are not this precise but I do it here because in order to compare this result to that of analzying the data with a linear model. 

The effect of $Treatment$ can be modeled with the linear model

\begin{equation}
\textrm{E}[Recombinant\_fraction|Treatment] = \beta_0 + \beta_1 Treatment
(\#eq:categorical)
\end{equation}

The left side of this equation is read as "the expected recombinant fraction conditional on Treatment" and can be thought of as "the expected recombinant fraction for a specific treatment level is equal to...". Perhaps surprisingly, this is the same model as that used for the squirrel fecal cortical metabolites, which is, more generally $\textrm{E}[Y|X] = \beta_0 + \beta_1 X$.

What are the estimates of $\beta_0$ and $\beta_1$?

```{r echo=FALSE, fly_coefficients}
coefficients(summary(fit_recombinant))
```

Compare the column "Estimate" with the group means and difference in means computed above. The estimate of the intercept is the mean of the Wounded group. The estimate of the $Treatment$ coefficient is the difference in means. That is,

**In a linear model with a categorical $X$, the coefficients ($b_0$ and $b_1$) are a mean and a difference in means.**

The coefficients in the model with categorical $X$ are also an intercept and slope, and this is explored in the problems at the end of the chapter, but it is not especially useful to think of them in this way. In both kinds of models (categorical and continous $X$), we are generally less interested in $b_0$ and more interested in $b_1$ -- the effect of $X$.

For the recombinant fly experiment, the effect of bacteria infection is 0.03, or 3 additional recombinants per 100 offspring. The SE of this effect (0.016) is our measure of uncertainty. The SE is used to compute the 95% confidence interval in the top part of figure \@ref(fig:recombinantFlyPlot). The interval contains the range of effects that are consistent with the data. This range includes values up to about 6% and down to about 0%. Importantly, negative values (other than very small ones) are not consistent with the data.

### "Statistical model" not "regression model"

Statistical modeling terminology can be confusing. The $X$ variables in a statistical model may be quantitative (continuous or integers) or categorical (names or qualitative amounts) or some mix of the two. Linear models with all quantitative independent variables are often called "regression models." Linear models with all categorical independent variables are often called "ANOVA models". Linear models with a mix of quantitative and categorical variables are often called "ANCOVA models" if the focus is on one of the categorical $X$ or "regression models" if there tend to be many independent variables. These names reflect the history of the development of the different kinds of linear models. I advocate using the term "statistical model" for general usage and "linear model" for more specific use, regardless of the combination of variable types.

## Statistical modeling vs. Null hypothesis testing

Most biostatistics textbooks for biologists guide a student/researcher toward the "correct" statistical test for experimental data. The concept of a statistical test of inference is explored more in Appendix xxx but for now, a typical textbook would probably steer a researcher into analzying the recombinant fly data with a t-test of the difference between means.

```{r}
fly_t <- t.test(Recombinant_fraction ~ Treatment, data=sub_fly, var.equal=TRUE)
fly_t.p <- fly_t$p.value
fly_t.t <- abs(fly_t$statistic)
```

The output of a *t*-test is a test statistic (*t*) and a *p*-value, which, roughly, is the probability of finding a test statistic as large or larger than the observed test statistic if we were to repeat the experiment many, many times using hypothetical data in which there is no effect. This hypothetical data with no effect is the **null hypothesis**.^[The effect in the null hypotheses can be any pre-specified value. The nil null (zero effect) is the most common] A very small *p* (say 0.01 or 0.0001) would be unlikely if the null hypothesis were true, and, consequently, a very small *p* is evidence "against the null" (or evidence that a low-probability event occurred, but we don't have additional evidence for this so this conclusion is generally dismissed). Again, researchers typically conclude that a difference is "statistically significant" if *p* is less than 0.05 and, consequently, the treatment has "an effect".

The *t*-statistic for the fly recombinant data is `r fly_t.t` and the *p*-value is `r fly_t.p`, which means there is a 5.6% probability of finding *t* $\ge$ `r fly_t.t` if "the null were true". The *p*-value of 0.056 is a pretty small probability, and is close to but not smaller than 0.05, and so is not "statistically significant." How is this reported? If the researchers have an *a priori* hypothesis of an effect, they will often report a *p*-value of 0.056 as "marginally significant" or worse "trending toward significant" (why not trending "away"?). But if the researchers have an *a priori* hypothesis of no effect, then they will often report a *p*-value of 0.056 as simply "not significant" or worse "no effect" (see xxx why a *p*-value is not evidence of no effect).

Most importantly, no part of null hypothesis testing is concerned with estimating the effect size and our uncertainty in this estimate. Test statistics and *p*-values are not measures of effect size even though each is a function of effect size. This is because each is also a function of sample size and variation. A large *t* and small *p* could result from a large effect, or a large sample, or small variability. Null hypothesis testing encourages a focus on the trivia (presence or absence of an effect) instead of the information that we need to model a system. If we want to model the biological consquences of an intervention, such as a drug, or of changing conditions, such as ocean ocidification, or if we just want to model relationships within a system, then we need measures of effect size and uncertainty from statistical models. 

A *p*-value can is a useful, but limited tool, and a researcher can use the statistical model to test specific hypotheses if desired. The coefficients of the model are the simplest of these tests. Look at the column "Pr(>|t|)" in the table of coefficients from the recombinant fly experiment above. This column contains the probability of a *t*-test for each coefficient. The *p* value for $b_1$ (the Smarc treatment) is precisely the *p*-value for the *t*-test of the means. This is because the math behind a *t*-test is a special case of the linear model in model \@ref(eq:categorical). And the math behind ANOVA is a special case of the linear model. And the math behind regression is a special case of the linear model. In other words, there is little reason to learn these special cases as unrelated tests. There is no reason to teach (or learn) the dichotomous key to the tests of inference.

## Multilevel models

## Linear models versus non-linear models

In this text, I use "linear model" for any model that is linear in the parameters, which means that the different components of the model are added together. Or, using the language of matrix algebra, the predictor is a simple dot product of the model matrix and the coefficients. For example, a cubic polynomial model

\begin{equation}
Y = \beta_0 + \beta_1 X + \beta_2 X^2 + \beta_3 X^3 + \varepsilon
\end{equation}

is a linear model, even though the function is non-linear, because the different components are added (or, using matrix algebra, the predictor is $\mathbf{X}\boldsymbol{\beta}$).

A generalized linear model (GLM) has the form $g(\mu_i) = \eta_i$ where $\eta$ (the greek letter eta) is the linear predictor, which is linear in the parameters.

\begin{equation}
\eta = \mathbf{X}\boldsymbol{\beta} 
\end{equation}

Many sources do not consider a GLM to be a "linear model" but an "extension" of a linear model. Regardless, a GLM is linear in the parameters and in this textbook, I include GLMs under the "linear model" umbrella.

Non-linear models, in conrast to a GLM or classical linear model, are not linear in the parameters (the predictor is not a simple dot product of the model matrix and a vector of parameters). For example, the Michaelis-Menten model is a nonlinear model

\begin{equation}
Y = \frac{\beta_1 X}{\beta_2 + X} + \varepsilon
\end{equation}



