# Plotting Models

*So, along the lines of Sarah Susanka’s “Not So Big House,” Kolbert asks the group, “What would a Pretty Good House look like?”* -- Michael Maines^["The Pretty Good House - Finding the right balance between construction cost and energy performance". https://www.greenbuildingadvisor.com/article/the-pretty-good-house]

```{r plots-setup, echo=FALSE, message=FALSE}

library(here)
library(janitor)
library(readxl)
library(data.table)
library(stringr)
library(dplyr) # recode

# analysis packages
library(nlme)
library(emmeans)
library(car) # qqplot, spreadlevel
library(lmPerm)

# graphing packages
library(ggplot2) # ggplot environment
library(ggpubr) # publication ready plots
library(ggforce) # jitter
library(ggsci) # color palettes
library(ggpubfigs) # color palettes
# execute this command only the first time you use ggpubfigs
# devtools::install_github("JLSteenwyk/ggpubfigs")
library(cowplot) # combine plots
library(lazyWeave) # pretty pvalues
library(broom)


here <- here::here
data_folder <- "data"

# Okabe & Ito palette
ito_seven <- friendly_pal("ito_seven") # ggpubfigs
pal_okabe_ito <- ito_seven[c(6,5,3,7,1,2,4)] # order of Wilke


odd <- function(x) x%%2 != 0
even <- function(x) x%%2 == 0

```

Plots should be the focus of both the reader and researcher. Instead of mindless plotting, a researcher should ask a series of questions of every plot

1. What is the point of each element in a plot?
2. Are these the points that I most want to communicate?
3. Are there better practices for communicating these points?
4. Are the points that I want to communicate that are not covered by these elements?

The answer to these questions should inform what is and what is not plotted. The result is a pretty good plot. The idea of a pretty good plot is borrowed from the "pretty good house" concept that grew out of a collaborative group of builders and architects in Northern New England. The "pretty good house" combines best practices for building an earth friendly, high performance home at a reasonable cost. There is no pretty good house governing body that awards certificates of achievement but, instead, a set of metrics and a collection of building practices that can achieve these.

A typical pretty good plot contains some combination of

1. Modeled effects with confidence intervals. "Effects" are the coefficients of a model, or contrasts constructed from the model, such as pairwise differences between the means of the levels of a factor. Inferences are typically made from the estimated effects
2. Modeled means and standard errors or confidence intervals.
3. Raw data points or a summary distribution of these.

## Pretty good plots show the model and the data

The data to introduce best practices in plotting come from Figure 2d and Figure 2e from "ASK1 inhibits browning of white adipose tissue in obesity", introduced in the introductor chapter (Analyzing experimental data with a linear model)

```{r plots-import-functions, echo=FALSE}
# function to read in parts of 2b
import_fig_2_part <- function(range_2){
  fig_2_part <- read_excel(file_path,
                          sheet = "Source Date_Figure 2",
                          range = range_2,
                          col_names = TRUE) %>%
    data.table()
  group <- colnames(fig_2_part)[1]
  setnames(fig_2_part, old = group, new = "treatment")
  fig_2_part[, treatment := as.character(treatment)] # this was read as logical
  fig_2_part[, treatment := group] # assign treatment group
  fig_2_part[, mouse_id := paste(group, .I)]
  return(fig_2_part)
}

```

```{r plots-AUC-functions, echo=FALSE}
# script to compute various area under the curves (AUC) using trapezoidal method
# le Floch's "incremental" auc substracts the baseline value from all points.
# This can create some elements with negative area if post-baseline values are less
# than baseline value.
# Some researchers "correct" this by setting any(y - ybar < 0 to zero. Don't do this.

auc <- function(x, y, method="auc", average = FALSE){
  # method = "auc", auc computed using trapezoidal calc
  # method = "iauc" is an incremental AUC of Le Floch
  # method = "pos_iauc" is a "positive" incremental AUC of Le Floch but not Wolever
  # method = "post_0_auc" is AUC of post-time0 values
  # if average then divide area by duration
  if(method=="iauc"){y <- y - y[1]}
  if(method=="pos_iauc"){y[y < 0] <- 0}
  if(method=="post_0_auc"){
    x <- x[-1]
    y <- y[-1]
  }
  n <- length(x)
  area <- 0
  for(i in 2:n){
    area <- area + (x[i] - x[i-1])*(y[i-1] + y[i])
  }
  value <- area/2
  if(average == TRUE){
    value <- value/(x[length(x)] - x[1])
  }
  return(value)
}

```


```{r plots-fig2e-file-path, echo=FALSE}
data_from <- "ASK1 inhibits browning of white adipose tissue in obesity"
file_name <- "41467_2020_15483_MOESM4_ESM.xlsx"
file_path <- here::here(data_folder, data_from, file_name)
  
fig_2_sheet <- "Source Date_Figure 2"
```

```{r plots-fig2e-import, echo=FALSE, message=FALSE, warning=FALSE}

range_list <- c("A179:H189", "A191:H199", "A201:H214", "A216:H230")
fig_2e_wide <- data.table(NULL)
for(range_i in range_list){
  part <- import_fig_2_part(range_i)
  fig_2e_wide <- rbind(fig_2e_wide,
                       part)
}
fig_2e_wide[, c("ask1", "diet") := tstrsplit(treatment, " ", fixed=TRUE)]

# melt
fig_2e <- melt(fig_2e_wide,
               id.vars = c("treatment",
                           "ask1",
                           "diet",
                           "mouse_id"),
               variable.name = "time",
               value.name = "glucose")
fig_2e[, time := as.numeric(as.character(time))]

# for plot only (not analysis!)
shift <- 2
fig_2e[treatment == "ASK1F/F chow", time_x := time - shift*1.5]
fig_2e[treatment == "ASK1Δadipo chow", time_x := time - shift*.5]
fig_2e[treatment == "ASK1F/F HFD", time_x := time + shift*.5]
fig_2e[treatment == "ASK1Δadipo HFD", time_x := time + shift*1.5]
```

```{r plots-fig2e-auc, echo=FALSE}
# AUC of post-baseline values
# do this after melt as we don't need this in long format)
fig_2e_wide[, glucose_0 := get("0")]

times <- c(0, 15, 30, 45, 60, 90, 120)
time_cols <- as.character(times)
Y <- fig_2e_wide[, .SD, .SDcols = time_cols]
fig_2e_wide[, glucose_auc := apply(Y, 1, auc,
                           x=times,
                           method = "auc",
                           average = FALSE)]
fig_2e_wide[, glucose_mean := apply(Y, 1, auc,
                           x=times,
                           method = "post_0_auc",
                           average = TRUE)]

```

```{r plots-fig2e-fit-model, echo=FALSE}
# fit the model
fig2e_m1 <- lm(glucose_mean ~ glucose_0 + ask1*diet,
               data = fig_2e_wide,
               na.action = "na.exclude")

# coef table
fig2e_m1_coef <- cbind(coef(summary(fig2e_m1)),
                       confint(fig2e_m1))
# emm table
fig2e_m1_emm <- emmeans(fig2e_m1, specs = c("ask1", "diet"))

# contrast table
fig2e_m1_pairs <- contrast(fig2e_m1_emm,
                           method = "revpairwise",
                           adjust = "none",
                           simple = "each",
                           combine = TRUE
                           ) %>%
  summary(infer = TRUE)

# calculate adjusted values at mean of chow/ASK1F/F
ycols <- c("ask1", "diet", "glucose_0", "glucose_mean")
new_data <- fig_2e_wide[, .SD, .SDcols = ycols]
control_glucose_0 <- mean(fig_2e_wide[treatment == "ASK1F/F chow", glucose_0])
new_data[, glucose_0 := control_glucose_0]
fig_2e_wide[, glucose_mean_adj := predict(fig2e_m1, new_data)
            + residuals(fig2e_m1)]


```

### Pretty good plot component 1: Modeled effects plot

```{r plots-prepare-fig2e-effects, echo = FALSE, message=FALSE}
# reverse order of rows so flipped plot has original order
fig2e_pairs_plot_order <- data.table(fig2e_m1_pairs)[rev(1:.N)]

# order "contrast" factor as in table!
# create contrast list by hand with copy and paste
contrast_list_1 <- c("ASK1Δadipo: HFD - chow",
                   "ASK1F/F: HFD - chow",
                   "HFD: ASK1Δadipo: ASK1Δadipo - ASK1F/F",
                   "chow: ASK1Δadipo - ASK1F/F")
contrast_list_2 <- c("ASK1Δ: HFD - chow",
                   "ASK1F/F: HFD - chow",
                   "HFD: ASK1Δ - ASK1F/F",
                   "chow: ASK1Δ - ASK1F/F")

fig2e_pairs_plot_order[, effect := factor(contrast_list_2,
                                      contrast_list_2)]


# add the interaction row
interaction_row <- fig2e_m1_coef["ask1ASK1Δadipo:dietHFD",
                                            c("Estimate", 
                                              "Pr(>|t|)",
                                              "2.5 %",
                                              "2.5 %")]
interaction_row <- data.table(effect = row.names(fig2e_m1_coef),
                              fig2e_m1_coef)[4]
interaction_row[1, effect := "Diet:ASK1 interaction"]
setnames(interaction_row, 
         old = c("Estimate",
                 "Std. Error",
                 "Pr(>|t|)",
                 "2.5 %",
                 "97.5 %"),
         new = c("estimate",
                 "SE",
                 "p.value",
                 "lower.CL",
                 "upper.CL"))

fig2e_pairs_plot_order <- rbindlist(list(interaction_row,
                                         fig2e_pairs_plot_order),
                                    fill = TRUE)

# make sure of order of factor levels for plot
level_order <- fig2e_pairs_plot_order[, effect]
fig2e_pairs_plot_order[, effect := factor(effect, level_order)]

# pretty p-values
fig2e_pairs_plot_order[, p_pretty := pvalString(p.value)]

# group columns for p-value brackets
fig2e_pairs_plot_order[, group1 := c(0, 4, 3, 4, 2)]
fig2e_pairs_plot_order[, group2 := c(0, 2, 1, 3, 1)]

```

```{r plots-fig2e-gg-effects, echo=FALSE}
# get bounds for y-axis
min_bound <- min(fig2e_pairs_plot_order[, lower.CL])
max_bound <- min(fig2e_pairs_plot_order[, upper.CL])
y_lo <- min(min_bound+min_bound*0.2,
            -max_bound)
y_hi <- max(max_bound + max_bound*0.2,
            -min_bound)
y_lims <- c(y_lo, y_hi)
y_lims <- c(-6, 9)

fig2e_gg_effect <- ggplot(data=fig2e_pairs_plot_order, 
                          aes(x = effect,
                              y = estimate)) +
  # confidence level of effect
  geom_errorbar(aes(ymin=lower.CL, 
                    ymax=upper.CL),
                width=0, 
                color="black") +
  # estimate of effect
  geom_point(size = 3) +
  
  # zero effect
  geom_hline(yintercept=0, linetype = 2) +
  
  # p-value
  annotate(geom = "text",
           label = fig2e_pairs_plot_order$p_pretty,
           x = 1:5,
           y = 9) +
  
  # aesthetics
  scale_y_continuous(position="right") +

  coord_flip(ylim = y_lims) + 
  theme_pubr() +
  ylab("Effects (mmol/L)") +
  theme(axis.title.y = element_blank()) +
  NULL

fig2e_gg_effect
```

Biologists infer the biological consequences of a treatment by interpreting the magnitude and sign of treatment "effects", such as the differences in means among treatment levels. Why then do we mostly plot treatment level means, where effect magnitude and sign can only be inferred *indirectly*, by mentally computing differences in means? A pretty good plot *directly* communicate treatment effects and the uncertainty in the estimates of these effects using an **effects plot**.

Figure \@ref(plots-fig2e-gg-effects) is an effects plot of the linear model fit to the glucose tolerance data. The effects plot is "flipped". The y-axis is the categorical variable -- it contains the labels identifying the pair of groups in the contrast and the direction of the difference. In addition to the pairwise comparisons, I include the interaction effect on the y-axis. The x-axis is the continuous variable -- it contains the **simple effects**, which is the difference in means between the two groups identified by the y-axis labels. Additionally, the y-axis includes the estimate of the $diet \time genotype$ interaction effect. The bars are 95% confidence intervals of the effects (either simple effects or interaction effect), which is the range of values that are compatible with the observed data at the 95% level.

We can use the effects and CIs of the effects to evaluate the treatment effects. For example, when on a high fat diet (HFD), the mean, post-baseline plasma glucose level in the ASK1$\Delta$adipo is 3.5 mmol/L less than that for the control (ASK1F/F). Differences less than 5.3 mmol/L less than ASK1F/F levels or greater than 1.7 mmol/L less than ASK1F/F levels are not very compatible with the data. It is up to the research community to decide if 1.7 mmol/L or 3.5 mmol/L differences are physiologically meaningful effects.

### Pretty good plot component 2: Modeled mean and CI plot

```{r plots-fig2-gg-response, echo=FALSE}
# use a data.table version of fig2e_m1_emm for plot
fig2e_m1_emm_dt <- summary(fig2e_m1_emm) %>%
  data.table

pd <- position_dodge(1)
fig2e_gg_response <- ggplot(data = fig_2e_wide,
                            aes(x = diet,
                                y = glucose_mean,
                                color = ask1)) +
  
  # points
  geom_sina(alpha = 0.5) +
  
  # plot means and CI
  geom_errorbar(data = fig2e_m1_emm_dt,
                aes(y = emmean,
                    ymin = lower.CL,
                    ymax = upper.CL,
                    color = ask1),
                width = 0,
                position = pd
  ) +
  
  geom_point(data = fig2e_m1_emm_dt,
             aes(y = emmean,
                 color = ask1),
             size = 3,
                position = pd
  ) +

  # aesthetics
  ylab("Post-baseline glucose (mmol/L)") +
  scale_color_manual(values = pal_okabe_ito,
                     name = NULL) +
  theme_pubr() +
  theme(legend.position = c(0.25, 0.9)) +
  theme(axis.title.x = element_blank()) +
  
  NULL

fig2e_gg_response
```

```{r plots-fig2-gg-response-adjusted, echo=FALSE}
# use a data.table version of fig2e_m1_emm for plot
fig2e_m1_emm_dt <- summary(fig2e_m1_emm) %>%
  data.table

pd <- position_dodge(1)
fig2e_gg_response_adj <- ggplot(data = fig_2e_wide,
                            aes(x = diet,
                                y = glucose_mean_adj,
                                color = ask1)) +
  
  # points
  geom_sina(alpha = 0.5) +
  
  # plot means and CI
  geom_errorbar(data = fig2e_m1_emm_dt,
                aes(y = emmean,
                    ymin = lower.CL,
                    ymax = upper.CL,
                    color = ask1),
                width = 0,
                position = pd
  ) +
  
  geom_point(data = fig2e_m1_emm_dt,
             aes(y = emmean,
                 color = ask1),
             size = 3,
                position = pd
  ) +

  # aesthetics
  ylab("Post-baseline glucose\nadjusted for baseline (mmol/L)") +
  scale_color_manual(values=pal_okabe_ito,
                     name = NULL) +
  theme_pubr() +
  theme(legend.position = c(0.25, 0.9)) +
  theme(axis.title.x=element_blank()) +
  
  NULL
fig2e_pairs_plot_order[, group1 := group1/2+0.25]
fig2e_pairs_plot_order[, group2 := group2/2+0.25]

fig2e_gg_response_adj_p <- fig2e_gg_response_adj +
  stat_pvalue_manual(fig2e_pairs_plot_order[2:5,],
                     label = "p_pretty", 
                     y.position=c(28, 26.5, 25, 25),
                     tip.length = 0.01) +
  theme(legend.position = "top")

 fig2e_gg_response_adj_p
```

The response plot in Figure \@ref(fig:plots-fig2-gg-response-adjusted) "shows the model" -- by this I mean the plot shows the *modeled* means, represented by the large circles, the *modeled* 95% confidence intervals of each mean, represented by the error bars, and the *model-adjusted* individual response values, represented by the small colored dots. What do I mean by *modeled* means, modeled error intervals, and model-adjusted responses?

```{r plots-model-means-table, echo=FALSE}
# sample means and SE
fig2e_summary <- fig_2e_wide[, .(N = .N,
                                 glucose_mean = mean(glucose_mean),
                                 sigma = sd(glucose_mean),
                                 SE = sd(glucose_mean)/sqrt(.N)),
                       by = c("ask1", "diet")]
setnames(fig2e_summary,
         old = c("glucose_mean", "sigma", "SE"),
         new = c("Sample mean", "Sample sigma", "Sample SE"))
fig2e_m1_emm_dt[, sigma := summary(fig2e_m1)$sigma]
ycols <- c("emmean", "sigma", "SE", "ask1", "diet")
fig2e_summary <- merge(fig2e_summary,
                       fig2e_m1_emm_dt[, .SD, .SDcols = ycols],
                       by = c("ask1", "diet"))
setnames(fig2e_summary,
         old = c("emmean", "sigma", "SE"),
         new = c("Model mean", "Model sigma", "Model SE"))
knitr::kable(fig2e_summary, digits = c(1,1,0,1,2,2,1,2,2))
```

1. The modeled means and error intervals are estimated from the statistical model. Many published plots show the sample means and sample error intervals, which are computed within each group independently of the data in the other groups and are not adjusted for any covariates or for any hierarchical structure to the data.
2. A modeled mean will often be equal to the raw mean, but this will not always be the case. The modeled means in post-baseline glucose data in Figure () do not equal the sample means because the modeled means are adjusted for the baseline measures of glucose (Table \@ref(tab:plots-model-means-table)).
3. For most of the analyses in this text, modeled error intervals are not the same as the sample error intervals and are commonly conspicuously different. For the glucose tolerance data, the modeled error intervals are calculated from a pooled estimate of $\sigma$ while the sample error intervals are estimated from sample-specific estimates of $\sigma$ (Table \@ref(tab:plots-model-means-table)).
4. Model-adjusted responses are responses that are adjusted for covariates in the model. If there are no covariates in the model, the model-adjusted responses are the same as the raw response. In the glucose tolerance data, the model-adjusted responses are the modeled, individual response measures if all individuals had the same baseline glucose (the covariate).

Modeled means, error intervals, and responses are not commonly plotted but it is these values that are consistent with our inferences from the statistical model. There are many data sets in experimental biollgy where a plot of sample means, error intervals, and responses give a very distorted view of inference from the model.

The response plot in Figure \@ref(fig:plots-fig2-gg-response-adjusted) also "shows the data" by plotting response values as "jittered" dots. Showing the data

1. allows the reader to get a sense of the underlying sample size and distribution including outliers, which can be used to mentally model check the published statistical analysis. Adding a box plot, violin plot, or dot plot augments the communication of the distributions if there are enough data to justify the addition.
2. allows a reader to see the overlap in individual responses among groups and to evaluate the biological consequences of this overlap.

### Combining Effects and Modeled mean and CI plots -- an Effects and response plot.

```{r plots-fig2e-ggplot, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Effect of diet and ASK1 deletion on post-baseline glucose. Top: effects plot of 2 X 2 simple effects (difference in means) and of the diet X genotype interaction. Bars are 95% confidence intervals of the effects. Unadjusted p-values from the linear model are given. Bottom: response plot of the means and 95% confidence interval of each diet X genotype combination."}
fig2e_fig <- plot_grid(fig2e_gg_effect,
                       fig2e_gg_response_adj,
                       nrow=2,
                       align = "v",
                       axis = "l",
                       rel_heights = c(0.7,1))
fig2e_fig
```

Combining the effects and response plots into a single plot is an easy solution to issues that arise if only one or the other is used. What are these issues?

While a response plot like that in Figure \@ref(fig:plots-fig2-gg-response-adjusted) is standard in biology, it fails to show the effects, and the uncertainty in the effects, *explicitly*. To infer the effects from the plot, a reader must perform mental math -- either compute the difference or the ratio between pairs of means. This mental math is easy enough if the comparisons are between individual treatment levels but much harder if the comparisons are between pooled sets of treatment levels, for example in a factorial experimental design. The mental math that is excessively difficult is the reconstruction of some kind of error interval of the contrasts, for example the 95% confidence intervals in Figure \@ref(plots-fig2e-gg-effects) and it is these intervals that are necessary for a researcher to infer the range of biological consequences that are compatible with the experiment's results. The inclusion of the *p*-values for all pairwise comparisons in a response plot gives the significance level of these contrasts, but of the kinds of summary results that we could present (contrasts, error intervals, *p*-values), the *p*-values are the least informative.

Effects plots are very uncommon in most of biology outside of meta-analysis and clinical medicine more generally. An effects plot alone fails to communicate anything about the sample size or conditional distribution of the data. Equally important, response values are often meaningful and researchers working in the field should be familiar with usual and unusal values. This can be useful for interpreting biological consequences of treatment effects but also for researchers and readers to asses the credibility of the data (for example, I have twice, once in my own data and once in a colleagues, found mistakes in the measuement of an entire data set of response variable because the plotted values weren't credible).

## Some comments on plot components

1. Several recent criticsms of bar plots have advocated box plots or violin plots as alternative. Box plots and violin plots are useful alternatives to jittered dots if there are sufficient data to capture the distribution but I wouldn't advocate replacing the plot of modeled means and confidence intervals with box or violin plots, as these communicate different things. More importantly, box and violin plots do not communicate the treatment effects.
2. Almost all plots in biology report the error bars that represent the sample standard error. As described above, sample standard error bars do not reflect the fit model and can be highly misleading, at least if interpreting as if they do reflect the model. Also, sample standar error bars can explicitly include absurd values or imply absurd confidence intervals. For example, I sometimes see standard error bars cross $y=0$ for a response that cannot be negative, such as a count. Even if the standard error bar doesn't cross zero, it is common to see standard error bars that imply (but do not explicitly show) 95% confidence intervals that cross zero, again for responses that cannot be negative. A standard error bar or confidence interval that crosses zero implies that negative means are compatible with the data. This is an absurd implication for responses that cannot have negative values (or are "bounded by" zero). Explicit or implicit error bars that cross zero are especially common for count responses with small means. *If* a researcher plots confidence intervals, these should be computed using a method that avoids absurd implications, such methods include the bootstrap and generalized linear models.
3. **Stars add minimal value**. Many researchers add star symbols to a plot indicating the level of significance of a particular paired comparison. An uncommon, but better, alternative would be to add the actual p-value (as above). A much more valuable alternative is to report the effects and uncertainty in an effects plot or a combined effects-and-response plot.

## Working in R

A reasonable goal of any research project should be a script to generate the final plots entirely within the R environment and not rely on external drawing software to add finishing features. This section covers some of the basics of using R packages to create plots. Later chapters cover some of the details that are specific to the analyses in that chapter.

[ggplot2](https://ggplot2.tidyverse.org) is one of the major plotting environments in R and the one that seems to have the strongest following, especially among new R users. ggplot2 has the ability to generate extremely personalized and finished plots. However, creating a plot with multiple layers (bars, lines, error intervals, raw data points, p-values, text annotations) can often require many hours of googling.

[ggpubr](https://cran.r-project.org/web/packages/ggpubr/index.html) is an extension to ggplot2 (it calls ggplot2 functions under the hood) and provides many canned functions for producing the kinds of ggplots that are published in biological journals. With one line of script, a researcher can generate a publishable plot that is as good or better than many published plot.


**Here I show how to add custom (ggplot2) features to a ggpubr plot**

Throughout this book, ggpubr is used to create a basic plot and then additional features are added to the basic plot using ggplot2 functions.

### Source data

Data source: [ASK1 inhibits browning of white adipose tissue in obesity](https://www.nature.com/articles/s41467-020-15483-7){target="_blank"} 

The source data are that for Figure 2E. The response is glucose $AUC$ the "area under the curve" of repeated measures of blood glucose during the 120 minutes of a glucose tolerance test. Glucose $AUC$ is a measure of glucose tolerance, the higher the area, the higher the blood glucose over the two hours, and the worse the physiological response to a sudden rise in blood glucose. There are two treatment factor variables, $Diet$ ("chow", "HFD"), where chow is normal mouse chow and "HFD" is a high fat diet, and $ask1$ ("ASK1F/F", "ASK1Δadipo") where "ASK1F/F" is the control level and "ASK1Δadipo" is the ASK1 adipose-deletion mouse described in Chapter 1.

#### Import

```{r plots-fig2e-import, echo=TRUE, message=FALSE, warning=FALSE}

data_from <- "ASK1 inhibits browning of white adipose tissue in obesity"
file_name <- "41467_2020_15483_MOESM4_ESM.xlsx"
file_path <- here::here(data_folder, data_from, file_name)
  
# the data are in "tranposed" format -- each row contains the n
# measures of a treatment level. Read, then transpose
# to make the treatment levels the columns
fig_2e_wide <- read_excel(file_path,
                     sheet = "Source Date_Figure 2",
                     range = c("A233:O236"), # lot of NA
                     col_names = FALSE) %>%
  data.table %>%
  transpose(make.names = 1) # turn data onto 

# melt the four columns into a single "glucose_auc" column
# and create a new column containing treatment level.
y_cols <- colnames(fig_2e_wide)

# melt
fig_2e <- melt(fig_2e_wide,
               measure.vars = y_cols,
               value.name = "glucose_auc",
               variable.name = "treatment")

# create two new columns that are the split of treatment
fig_2e[, c("ask1", "diet") := tstrsplit(treatment,
                                        " ",
                                        fixed=TRUE)]

# since glucose_auc is the only response variable in this
# data.table, omit all rows with any NA
fig_2e <- na.omit(fig_2e)
# View(fig_2e)
```

### Response plot with sample SE bars or confidence intervals
`ggplot2` and `ggpubr` use sample error intervals (standard error bars and confidence intervals).

```{r plots-unpooled, fig.cap="(A) Mean and 1 SE error bar. (B) Mean and 95% CI."}
gg1 <- ggstripchart(data = fig_2e,
                 x = "treatment", 
                 y = "glucose_auc", 
                 add = c("mean_se"),
                 fill = "steelblue"
)

gg2 <- ggbarplot(data = fig_2e,
                 x = "treatment", 
                 y = "glucose_auc", 
                 add = c("mean_ci"),
                 fill = "steelblue"
)
plot_grid(gg1, gg2, ncol = 2, labels="AUTO")
```

### Adding bootstrap intervals

A bootstrap CI uses resamples of the data to estimate the interval and is a better choice than the default CI for data such as counts and proportions. The plot below uses ggpubr to create a stripchart of the data and the color of the data points are "de-emphasized" -- in order to emphasize the mean and CI -- by making them more transparent (using the argument `alpha`). `alpha` is added before the argument to add the mean in order to no de-emphasize the mean.

```{r plot-boot-plot, fig.cap="Sample means with bootstrapped 95% confidence intervals."}
set.seed(1)
gg.boot <- ggstripchart(data = exp2d,
                   x = "donor", 
                   y = "count", 
                   alpha = 0.4,
                   add = "mean"
) + 
  stat_summary(fun.data = "mean_cl_boot", 
               geom = "errorbar", 
               width = 0.1) +
  NULL


gg.boot
```

### Adding modeled means and error intervals

This section is extremely important for implementing the work flow advocated in this text. The goal is to plot the modeled means with some sort of error interval, typically a confidence interval, *and* to show the data or a summary of the data in a single plot. The procedure is

1. fit the model
2. use the fit model to estimate the modeled means and confidence limits using `emmeans` from the [emmeans package](https://cran.r-project.org/web/packages/emmeans/index.html).
3. use the `emmean` object to estimate the contrasts of interests using the `contrast` function from emmeans.
4. Use the objects from steps 2 and 3 to plot the modeled means

**Step 1: Fit the model**. A negative binomial, generalized linear model with log-link is fit to the count data.

```{r plot-nb-fit}
m1 <- glm.nb(count ~ donor, data = exp2d)
coef(summary(m1))
```
* The estimates and SE are on the **link scale**, which means they are in log-transformed space (or "log space"). Exponentiate these with exp(x) to **backstransform** these to the the **response scale** which is the scale of the measurement (number of neutrophils).

**Step 2: Estimate the modeled means and confidence levels**. The second step is to pass the fit model object (m1) to `emmeans` to estimate the modeled means. 

```{r plot-nb-emm}
m1.emm <- emmeans(m1, specs="donor", type="response")
m1.emm
```

* We specify the means that we want to estimate with "specs =". Here, we want to estimate the means of the levels of $donor$.
* Because the linear predictor of the model is on the log scale, we use the "type" argument to specify that we want the means to be backtransformed to the **response scale**, which is the scale of the measurement (number of cells)
* It can be useful to convert the emmeans table m1.emm to a data.table (or data.frame or tibble) using `m1.emm <- data.table(m1.emm)`. **Bug alert** If you do this, the object cannot be passed to the next step, the `contrast` function. So if you want the emmeans table as a data.table, assign it to a different name, for example `m1.emm_dt <- data.table(m1.emm)`.

**Step 3: Compute the contrasts, with p-values and confidence levels**. Contrasts among levels, or combinations of levels, are computed by passing the emmeans object (m1.emm) to the `contrast` function.

```{r plot-nb-pairs1}
m1.pairs <- contrast(m1.emm, method = "revpairwise", adjust = "none") %>%
  summary(infer = c(TRUE, TRUE))
m1.pairs
```

* Here, we set "method" to "revpairwise" in order to compute contrasts among all pairs of levels of $donor$. There are $m = 4$ levels and so $m(m-1)/2 = 6$ pairwise contrasts. "revpairwise" is used instead of "pairwise" because the former sets the direction of the contrasts that include the reference as non-reference level minus reference level.
* I use the "adjust" argument to specify no *p*-value adjustment for multiple tests.
* the contrast object is then piped (%>%) to the summary function, where I pass to the argument "infer", that I want both the confidence intervals (the first TRUE) and *p*-values (the second TRUE)
* this step isn't necessary if we were plotting only modeled means and CIs but 1) we almost always want contrasts with a fit model and so that is done here as part of the uninterrupted work flow that this book advocates and 2) we do  use the *p*-values and CIs from this table (m1.pairs) in the final plot below.
* **Bug alert** again, the emmeans table m1.emm must be passed to `contrast` as an emmeans object. If you have converted this object to a data.table, you will get an error. See the last note in Step 2. 

**Step 4: Plot the modeled means and 95% error intervals**.

The code below first creates the stripchart using the ggpubr function and then adds the confidence intervals using `geom_errorbar` and means using `geom_point`. The stripchart uses the data in the exp2d data.table. The errorbar and mean use the values in m1.emm object created by the `emmeans` function. The `geom_errorbar` and `geom_point` functions require an "aesthetic" to tell ggplot which column contains the y values of the points to plot (the "x" values are still in the column "donor", which is a column in both the exp2d data.table and m1.emm). The name of the column containing the "y" values in m1.emm is "response".

```{r plot-nb-plot, warning=FALSE, message=FALSE, fig.cap="Modeled means and 95% confidence interval computed from a negative binomial generalized linear model."}
set.seed(1)
gg.nb <- ggstripchart(data = exp2d,
                 x = "donor", 
                 y = "count",
                 alpha = 0.4) +
  ylab("Neutrophil count") +
  geom_errorbar(data = summary(m1.emm), 
                aes(y = response,
                    ymin = asymp.LCL, 
                    ymax = asymp.UCL), 
                width = 0.1) +
  geom_point(data = summary(m1.emm), 
                aes(y = response), 
                size = 2) +
  NULL

gg.nb
```

Some notes on the plot code

* A column name passed to a `ggpubr` function must be in quotes but a column name passed to a `ggplot2` function cannot be in quotes
* **Bug alert**. The data passed to ggplot2 must be a data.frame. In order for the ggplot2 functions to use the m1.emm object, the object has to be passed as `summary(m1.emm)`.
* **Bug alert**. Because the m1.emm table does not have a column named "count", which is the "y" column specified in `ggstripchart`, you must supply a new "y" column name to the `aes` function of `geom_errorbar` and `geom_point`. This is the name of the column in the emmeans table containing the modeled means. In m1.emm, this name is "response" but it can take different names in different emmeans tables, depending on the fit model.

### Adding p-values

In this section, I show how to add *p*-values to a ggpubr plot using `stat_compare_means`. Because this function has only a limited set of models that can be used to compute the *p*-values, I don't find it very useful and instead recommend adding custom *p*-values from the fit model (or from a permutation test) using the method in the next section.

For this example, a "t.test" is used to compute the p-values. The mean and error are the sample-based estimates because these, and not the modeled estimates, are consistent with the t-test *p*-values.

```{r plot-p-values, fig.cap="t-test p-values for the plot of sample means and CIs. The p-values were computed using ggpubr's function stat_compare_means."}
compare_list <- list(c("sox10", "iap_mo"), c("sox10", "gf"), c("sox10", "wt"))

gg.sample <- ggstripchart(data = exp2d,
          x="donor", 
          y="count",
          alpha = 0.4,
          add = c("mean_ci")) +
  stat_compare_means(method = "t.test", comparisons = compare_list) +
  ylab("Neutrophil count") +
  NULL

gg.sample
```

Notes on the code

* The pairs to compare with a *p*-value are specified with `comparison =`. The order of the pairs in the list function determine the order plotted from bottom (lowest on the y-axis) to top (highest on the y-axis).

* **It is important to know what exactly is being computed when analyzing data and reporting results** and "t test" is not sufficient to know this. The t-test could be the classic t-test or a Welch test. In this example, there are multiple comparisons and the standard error of the test statistic could be the pooled estimate from the linear model, or a pairwise estimate computed separately for each pair. And, given the multiple comparisons, the p-values could be adjusted or not. These kinds of questions can be checked with a function's help page. `?stat_compare_means` doesn't answer these questions but suggests `compare_means`, which also doesn't answer these questions. The script below has checks to see what p-values the function is returning. Run it in your session by changing the value of check_it to TRUE.

```{r}

# checks on the p-value
# t-tests using SE pooled over all four groups
check_it <- FALSE
if(check_it == TRUE){
  m1.lm <- lm(count~donor, data = exp2d)
  m1.lm.emm <- emmeans(m1.lm, specs="donor")
  contrast(m1.lm.emm, method="trt.vs.ctrl", ref = 4, adjust="none") # pooled SD
  
  pairwise.t.test(exp2d$count, exp2d$donor, p.adjust.method = "none", pool.sd = FALSE) # non-pooled SD
  # compare
  t.test(count~donor,
         data = exp2d[donor == "wt" | donor == "sox10"]) # matches, this is Welch t
  t.test(count~donor,
         data = exp2d[donor == "wt" | donor == "sox10"], var.equal = TRUE)
}

```

So, the *p*-values returned by `stat_compare_means(method="t.test")` are computed from independent (not pooled over the four groups) Welch t-tests.

### Adding custom p-values

If we want to add permutation *p*-values to the plot with bootstrapped CIs (\@ref(fig:plot-boot-plot) or add *p*-values from the generalized linear model to the plot of modeled means and CIs (\@ref(fig:plot-nb-plot), we need to use the function `stat_pvalue_manual` from the ggpubr package. In order to implement this, we need to add a step to the work flow path above

**Step 5: Add group columns and a column of formatted p-values to the contrast table**

The `stat_pvalue_manual` function needs to read a data frame with a columns labeled "group1" and "group2" that contain the pairs of levels to compare with a plotted p-value and a column "p" containing the nicely formatted p-values to add to the plot. There is no R function to create this table, but here is a script to add these to the contrast object returned by the `contrast` function of emmeans. In this example, I use m1.pairs from above and add the p-values to the plot of modeled means and CIs (\@ref(fig:plot-nb-plot).

First, we need these functions. Run these two lines to define the functions `odd` and `even`

```{r plots-functions}
odd <- function(x) x%%2 != 0
even <- function(x) x%%2 == 0
```

Second, we need to use these functions to add the columns. There are several R packages that provide functions to format *p*-values. Here, I use the function `pvalString` from the [lazyWeave](https://www.rdocumentation.org/packages/lazyWeave/versions/3.0.2/topics/pvalString) package. This script also uses `str_split` from the package [stringr](https://cran.r-project.org/web/packages/stringr/index.html).

```{r}
# convert m1.pairs to a data.table and assign to a new object, in order to
# keep a clean copy of m1.pairs
m1.pvalues <- data.table(m1.pairs)

# if the linear model is from a glm with log link, use this
groups <- unlist(str_split(m1.pvalues$contrast, " / "))
# add the group1 and group 2 columns
m1.pvalues[, group1 := groups[odd(1:length(groups))]]
m1.pvalues[, group2 := groups[even(1:length(groups))]]

# create a column of nicely formatted p-values for display.
m1.pvalues[, p := pvalString(p.value)]
```

**Bug alert** notes on the script to build the p-value table, if you don't want your code to fail.

* The script to extract the pair of group labels `str_split(m1.pvalues$contrast, " / "))` has to be written so that the characters within the quotes matches the characters separating the groups in the "contrast" column of the contrast table (here, m1.pairs). This will typically be either a space-minus-space or a space-slash-space. If the model fit is `lm` and the response is not transformed, then the correct code is `str_split(m1.pvalues$contrast, " - "))`. Regardless, look at the table to check. 
* In step 3 above, we took the contrast table object and passed it to the function `summary`, which converts the contrast table object to a data.frame. If we had skipped this step, `data.table(m1.pairs)` would fail. Instead, we'd have to use `data.table(summary(m1.pairs))`.

Now we can add the p-value to the ggplot object gg.nb created above. This is the beauty of a ggplot object (including those created by ggpubr), we can just keep adding stuff to it.

```{r plot-manual-p-values, fig.cap="Effects and means plot. Top panel: Effects (top panel) of treatments on neutrophil count. Bottom panel: modeled means of treatment levels with 95% confidence intervals."}

gg.nb <- gg.nb +
    stat_pvalue_manual(m1.pvalues[4:6,], # only show sox effects
                           label = "p", 
                           y.position=c(31, 28, 25)) +
  NULL

gg.nb
```

Notes on adding manual *p*-values to the plot:

* The pairs of groups to compare are specified by indexing the rows of m1.pvalues. Above, I limit the comparisons to those in rows 4-6. If I wanted to specify non-continous rows, I could use something like `m1.pvalues[c(1,3,5),]`, for example.
* The most manual part of adding manual p-values is setting the position for the brackets using the "position" argument. The values in this argument are the y-coordinates of the brackets. This may take some trial-and-error to position the brackets satisfactorily.

#### Modeled error intervals of the effect

For the plot of effects, we use table of contrasts m1.pairs as the data.

```{r, message=FALSE}
gg.effects <- ggdotplot(data = m1.pairs,
                        x = "contrast", 
                        y = "ratio", 
                        color = "steelblue",
                        fill = "steelblue",
                        size = 0.5) +
  
  geom_errorbar(aes(x = contrast, 
                    ymin = asymp.LCL, 
                    ymax = asymp.UCL),
                width = 0.15, 
                color="steelblue") +
  ylab("Effect ratio") +
  geom_hline(yintercept = 1, linetype = 2) +
  coord_flip() + 
  
  NULL

gg.effects
```

#### Combining effects and response plots

The ggplots are combined using `plot_grid` from the package [cowplot](https://cran.r-project.org/web/packages/cowplot/vignettes/introduction.html)

```{r, message=FALSE}
gg.effects <- gg.effects + scale_y_continuous(position = "right")
plot_grid(gg.effects, gg.nb, nrow = 2, align = "v", rel_heights = c(1, 2))

```


### Plotting two factors

The data are from figure 6d. This solution requires computing either the raw or modeled means and errors and adding these to a base ggpubr plot. Many packages have summary statistics functions for means, standard deviations, and standard errors. This is easily done by simply computing the statistics using data.table functionality.

```{r}
# compute raw statistics
# enclosing the line within parentheses prints the result to the console!
(exp6d.raw <- exp6d[!is.na(count), .(count = mean(count),
                       se = sd(count)/sqrt(.N)),
                   by=.(treatment, strain)]
)
```

Modeled means, standard errors, and confidence limits are conveniently computed using the `emmeans` ("estimated marginal means") function from the emmeans package. 

```{r}

# modeled statsistics
m1 <- glm.nb(count ~ treatment*strain, data = exp6d)
(m1.emm <- data.table(summary(emmeans(m1, specs = c("treatment", "strain"), type="response"))))
# change column "response" to "count" for the ggplot
setnames(m1.emm, old="response", new="count")
```

```{r}

#pairs_i <- list(c("sox10", "iap_mo"), c("sox10", "gf"), c("sox10", "wt"))
pd = position_dodge(0.7)
ggbarplot(x = "treatment", 
          y = "count",
          data = exp6d,
          add = c("mean"),
          color = "black",
          fill = "strain",
          palette = "jco",
          position = pd,
          size = 0.5) +
  #stat_compare_means(method = "t.test", comparisons=pairs_i) +
  ylab("Neutrophil count") +
  # geom_dotplot(aes(fill=strain),
  #              binaxis='y', stackdir='center', position=pd, show.legend=FALSE,
  #              color="grey") +
  geom_point(aes(fill = strain), position = position_jitterdodge(jitter.width = 0.2), show.legend = FALSE, alpha = 0.5) +
  geom_errorbar(data = m1.emm, aes(x = treatment, ymin = asymp.LCL, ymax = asymp.UCL, group = strain),
                position = pd, width = 0.1) +
  NULL


```


### Interaction plot

```{r}
#pairs_i <- list(c("sox10", "iap_mo"), c("sox10", "gf"), c("sox10", "wt"))

pd = position_dodge(0.2)
ggplot(data = m1.emm, aes(x = treatment, y = count, shape = strain, color = strain, group = strain)) +
  geom_point(position = pd, size = 3) +
  geom_errorbar(data = m1.emm, aes(x = treatment, ymin = asymp.LCL, ymax = asymp.UCL, group = strain),position = pd, width = 0.1) +
  geom_line(position = pd) +
  ylab("Neutrophil count") +
  scale_color_jco() +
  theme_pubr() +
  NULL

```

### Plot components
#### Showing the data

If there are only a few cases per group, there is little reason to summarize the distribution. Instead plot the individual points using a stripchart or a jitter plot

```{r}
# sample 4 points from each group to make it a small n experiment
inc <- exp2d[, .(inc = sample(min(.I):max(.I), 4)), by = donor][, inc]
ggstripchart(x = "donor",
             y = "count",
             alpha = 0.5,
             add = "mean",
             data = exp2d[inc,])
```

With more points, a stripchart can be okay but with too many points the distribution might be obscured. Reasonable alternatives are a box plot, a violin plot, and a dotplot.

```{r, message=FALSE}
gg1 <- ggstripchart(x = "donor",
          y = "count",
          fill="steelblue",
          data = exp2d)

gg2 <- ggboxplot(x = "donor",
          y = "count",
          fill = "steelblue",
          data = exp2d)

gg3 <- ggviolin(x = "donor",
          y = "count",
          fill = "steelblue",
          data = exp2d)
gg4 <- ggdotplot(x = "donor",
          y = "count",
          fill = "steelblue",
          data = exp2d)
plot_grid(gg1, gg2, gg3, gg4, nrow=2)
```

