# Plotting Models

*So, along the lines of Sarah Susanka’s “Not So Big House,” Kolbert asks the group, “What would a Pretty Good House look like?”* -- Michael Maines^["The Pretty Good House - Finding the right balance between construction cost and energy performance". https://www.greenbuildingadvisor.com/article/the-pretty-good-house]

```{r ggplot-setup, echo=FALSE, message=FALSE}
library(here) # needs to go after plyr so here() functions
library(janitor)
library(readxl)
library(data.table)
library(plyr) # mapvalues
library(stringr)
library(ggpubr) # plots
library(cowplot) # combine plots
library(ggsci) # scale color
library(lazyWeave) # pvalues
library(emmeans)
library(nlme)
library(lmerTest)
library(MASS)
library(gt)
library(DHARMa)

here <- here::here 
data_path <- "data" # bookdown

odd <- function(x) x%%2 != 0

even <- function(x) x%%2 == 0

```

When it comes to plotting, many researchers mindlessly generate plots that are easily generated by the software and look like the typical plots published in the field. The resulting plot is comforting because it is familiar, not because it effectively communicates what a good plot should communicate -- the model results.

Plots should be the focus of both the reader and researcher. Instead of mindless plotting, a researcher should ask a series of questions of every plot

1. What is the point of each element in a plot?
2. Are these the points that I most want to communicate?
3. Are there better practices for communicating these points?
4. Are the points that I want to communicate that are not covered by these elements?

The answer to these questions should inform what is and what is not plotted. The result is a pretty good plot. The idea of a pretty good plot is borrowed from the "pretty good house" concept that grew out of a collaborative group of builders and architects in Northern New England. The "pretty good house" combines best practices for building an earth friendly, high performance home at a reasonable cost. There is no pretty good house governing body that awards certificates of achievement but, instead, a set of metrics and a collection of building practices that can achieve these.

A typical pretty good plot contains some combination of

1. Modeled effects with confidence intervals. "Effects" are the coefficients of a model, or contrasts constructed from the model, such as pairwise differences between the means of the levels of a factor. Inferences are typically made from the estimated effects
2. Modeled means and standard errors or confidence intervals.
3. Raw data points or a summary distribution of these.

## Pretty good plots show the model and the data

The data to introduce best practices in plotting come from "The enteric nervous system promotes intestinal health by constraining microbiota composition"^[Rolig, A.S., Mittge, E.K., Ganz, J., Troll, J.V., Melancon, E., Wiles, T.J., Alligood, K., Stephens, W.Z., Eisen, J.S. and Guillemin, K., 2017. The enteric nervous system promotes intestinal health by constraining microbiota composition. PLoS biology, 15(2), p.e2000689]. The researchers found that zebrafish with a *sox10* mutation lacked an enteric nervous system and developed a microbiota-dependent inflammation. The paper includes several experiments to probe the hypothesis that the ENS regulates microbial community composition and, in turn, inflammatory status. The data here are from Fig. 2 of the paper, which reports the results of one of a set of experiments to test the hypothesis that microbiota from *sox10* mutants (that induce inflammation) are necessary and sufficient to induce inflammation in wildtype guts. In this experiment, homogenized intestines and their microbial community from four different donor groups were added to the flasks housing the zebrafish. The response variable is neutrophil count. Neutrophils are a white blood cell that increase in number during inflammation. The four treatment levels are the different donors of intestinal microbes: wt (wild type), gf (germ free, so no microbes are transferred), iap_mo (a control "for the possibility that nonbacterial factors such as host pro-inflammatory cytokines rather than microbial derived factors cause transmissible intestinal inflammation"), and sox10.

### Pretty good plot component 1: Modeled effects plot

Biologists infer the biological consequences of a treatment by interpreting the magnitude and sign of treatment "effects", such as the differences in means among treatment levels. Why then do we mostly plot treatment level means, where effects can only be inferred *indirectly*, by mentally computing differences in means? Instead, our primary plots should be effects plots, which *directly* communicate treatment effects, and the uncertainty in the estimates of these effects.

```{r plots-import, echo=FALSE}
folder <- "Data from The enteric nervous system promotes intestinal health by constraining microbiota composition"
filename <- "journal.pbio.2000689.s008.xlsx"

# figure 2D data
sheet_i <- "Figure 2"
range_i <- "F2:I24"
file_path <- here(data_path, folder, filename)
#file_path <- paste(data_path, folder, fn, sep="/")
dt_wide <- data.table(read_excel(file_path, sheet=sheet_i, range=range_i))
# clean names
dt_wide <- clean_names(dt_wide)
# get rid of "_donor"
setnames(dt_wide, old=colnames(dt_wide), new=gsub("_donor", "", colnames(dt_wide)))
# wide to long
exp2d <- na.omit(melt(dt_wide, measure.vars=colnames(dt_wide), variable.name="donor", value.name="count"))
exp2d[, donor:=factor(donor, c("wt", "gf", "iap_mo", "sox10"))]

# figure 6d data
sheet_i <- "Figure 6"
range_i <- "I2:L16"
file_path <- here(data_path, folder, filename)
#file_path <- paste(data_path, folder, fn, sep="/")
dt_wide <- data.table(read_excel(file_path, sheet=sheet_i, range=range_i))

# clean names
dt_wide <- clean_names(dt_wide)

exp6d <- na.omit(melt(dt_wide, measure.vars=colnames(dt_wide), variable.name="strain_by_treatment", value.name="count"))
exp6d[, strain:=mapvalues(strain_by_treatment,
                          from = c("wt", "sox10", "wt_transplant", "sox10_transplant"), 
                          to = c("wt", "sox10", "wt", "sox10"))]
exp6d[, treatment:=mapvalues(strain_by_treatment,
                          from = c("wt", "sox10", "wt_transplant", "sox10_transplant"), 
                          to = c("control", "control", "transplant", "transplant"))]
fit.nb <- glm.nb(count ~ strain*treatment, data=exp6d)
fit.emm <- emmeans(fit.nb, specs=c("strain", "treatment"), type="response")
show_tables <- FALSE
if(show_tables==TRUE){
  coef(summary(fit.nb))
  summary(contrast(fit.emm, method="revpairwise"), infer=c(TRUE, TRUE))
}
```


```{r plots-fit, echo=FALSE}
fit.nb <- glm.nb(count ~ donor, data=exp2d)
emm.nb <- emmeans(fit.nb, specs="donor", type="response")
effects.nb <- summary(contrast(emm.nb, method="revpairwise"), infer=c(TRUE, TRUE))

# pvalues
groups <- unlist(str_split(effects.nb$contrast, " / "))
group1 <- groups[odd(1:length(groups))]
group2 <- groups[even(1:length(groups))]

effects.nb <- data.table(group1=groups[odd(1:length(groups))],
                         group2=groups[even(1:length(groups))],
                         effects.nb)
# create column of labeled p-values
effects.nb[, p:=ifelse(p.value >= 0.01, round(p.value, 2),
                           ifelse(p.value > 0.001, round(p.value, 4),
                                  "<0.0001"))]
effects.nb[, order:=as.integer(effects.nb$contrast)]
setorder(effects.nb, order)
# convert to data.table for plot
emm.nb <- data.table(summary(emm.nb))
```


```{r plots-effect, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Effects Plot"}
pval <- effects.nb$p[as.integer(effects.nb$contrast)]
(gg1 <- ggdotplot(x="contrast", 
                 y="ratio", 
                 data=effects.nb, 
                 color = "steelblue",
                 fill = "steelblue",
                 size=0.5) +
  geom_errorbar(aes(x=contrast, ymin=asymp.LCL, ymax=asymp.UCL),
                width=0.15, color="steelblue") +
  ylab("Effect ratio") +
  geom_hline(yintercept=1, linetype = 2) +
  #stat_pvalue_manual(effects.nb, label = "p", y.position=c(20,20,20,20,20,20), remove.bracket=TRUE) +
  annotate("text", x = 1:6, y = c(20,20,20,20,20,20), label = effects.nb$p) +
  annotate("text", x=6.4, y=20, label="p-value") +
  annotate("text", x=(4:6+0.25), y=effects.nb$ratio[4:6], label=round(effects.nb$ratio[4:6],1)) +
  coord_flip() + 
  
  NULL)

```

The y-axis contains all pairwise comparisons among the four treatment levels. The x-axis is the response, which is the ratio of the means of the two groups in the comparison. For example, the top comparison shows that guts in fish exposed to sox10 donors have 2.7X more neutrophils per length of gut than guts in fish exposed to wild type donors. The bars are 95% confidence intervals, with is the range of effects that are compatible with the observed data at the 95% level (confidence intervals are disscussed in depth in chapter xxx.). The small end of the interval for the sox10/wt comparison is 1.31, meaning that effects as small as 31% increased neutrophil count are compatible with the data. It is up to the research community to decide if 2.7X or 1.31X are physiologically meaningful effects. *p*-values from the hypothesis tests are included.

### Pretty good plot component 2: Modeled mean and CI plot

Often the means of the treatment levels are meaningful, for example, if neutrophils per length of gut is a standard measure then researchers working in this area will be familiar with usual and unusal values. The data used in Fig \@ref(fig:plots-effect) are used to plot means and confidence intervals of the mean using a **bar chart**, which is a pretty good chart type for measures such as counts in which negative values are prohibited and zero is meaningful.

```{r plots-means, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Mean and error plot"}
gg2 <- ggbarplot(x="donor", 
          y="response", 
          data=emm.nb, 
          fill = "steelblue") +
  ylab("Count") +
  
  geom_errorbar(aes(x=donor, ymin=asymp.LCL, ymax=asymp.UCL),
                width=0.15) +
  
  geom_jitter(data=exp2d, aes(x=donor, y=count),
             color="black",
             width=0.1, height=0) +
  NULL
  
(gg2 + stat_pvalue_manual(effects.nb, label = "p", y.position=c(12, 15, 18, 28, 25, 31)))

```

Fig. \@ref(fig:plots-means) plots the *modeled* means, represented by the tops of the bars, the modeled 95% confidence intervals of each mean, represented by the error bars, and the *p*-values for all pairwise comparisons. What do I mean by *modeled* means and error intervals?

1. Modeled means and error intervals are estimated from the statistical model. Many published plots are of raw means and error intervals, meaning that the mean and error for each treatment level is computed only using the response measures in that treatment level.
2. A modeled mean will often be equal to the raw mean, but this will not always be the case, for example if there are covariates in the model (Chapter xxx).
3. Modeled error intervals are never the same as the raw error intervals, and are commonly conspicuously different. Almost always, we should plot modeled means and error intervals, since these represent the statistics that are relevant to inference.

Fig. \@ref(fig:plots-means) also plots the raw count data as "jittered" black dots. "Showing the data" is a pretty good feature of a plot because it allows the reader to get a sense of the underlying sample size and distribution including outliers, which can be used to mentally model check the published statistical analysis. For example, the jittered dots in Fig. \@ref(fig:plots-means) suggest a **heterogeneity** of variances; specifically, the treatment level with the largest mean has a conspicuously higher variance. This pattern violates the assumptions of a general linear model and should raise a red flag to a reader if the researchers used a general linear model to analyze the data.

What a mean-and-error plot fails to show, at least directly, are the effects. To infer the effects from the plot, a reader must perform mental math -- either compute the difference or the ratio between pairs of means. This mental math is easy enough if the comparisons are between individual treatment levels but much harder if the comparisons are between pooled sets of treatment levels, for example in a factorial experimental design. The mental math that is excessively difficult is the reconstruction of some kind of error interval of the contrasts, for example the 95% confidence intervals in Fig. \@ref(plots-effect) and it is this interval that is necessary for a researcher to infer the range of biological consequences that are compatible with the experiment. The inclusion of the *p*-values for all pairwise comparisons gives the significance level of these contrasts, but of the kinds of summary results that we could present (contrasts, error intervals, *p*-values), the *p*-values are the least informative.

### Combining Effects and Modeled mean and CI plots -- an Effects and response plot.

If one wants to show both effects and the data, then these can be combined.

```{r plots-harrellplot, echo=FALSE, message=FALSE, warning=FALSE, fig.asp = 1, fig.cap="A pretty good plot"}
gg_top <- gg1 + scale_y_continuous(position="right")
plot_grid(gg_top, gg2, nrow=2, align = "v", rel_heights = c(1, 1))

```

If the means do not have any importance in understanding the results, the effects plot can be combined with some kind of a plot summarizing the distribution, such as a boxplot.

```{r plots-harrelplot2, echo=FALSE, message=FALSE, warning=FALSE, fig.asp = 1, fig.cap="Another pretty good plot"}
gg3 <- ggboxplot(x="donor", 
          y="count", 
          data=exp2d
          ) +
  ylab("Count") +
  
  geom_jitter(data=exp2d, aes(x=donor, y=count),
             color="black",
             width=0.1, height=0) +
  NULL
  
plot_grid(gg_top, gg3, nrow=2, align = "v", rel_heights = c(1, 1))

```

Regardless, the effects plot is the most important component as this is the illustration of the story a researcher wants to tell.

## Some comments on plot components

1. **Alternatives to barplots make good plots for the supplement, not the main paper**. A prominent trend over the last few years has been the replacement of bar plots with plots that "show the data", such as jitter plots or dot plots, or that show summaries of the distribution, such as box plots or violin plots. These plot types were developed for exploratory data analysis, not to communicate the results of experiments. All of these plots fail to communicate the results of the statistical model and, because of this, are inferior to an effects plot, and even a mean-and-error plot, if the mean and error are the modeled values. Box/Violoin/Dot/Jitter plots are a useful supplement to an effects plot, either combined with the effects plot as above, or as a supplementary figure.
2. Standard error bars, computed from the raw data, can have absurd implications. For example, I sometimes see standard error bars cross $y=0$ for a response that cannot be negative, such as a count. Even if the standard error bar doesn't cross zero, it is common to see standard error bars that imply (but do not explicitly show) 95% confidence intervals that cross zero, again for responses that cannot be negative. A standard error bar or confidence interval that crosses zero implies that negative means are compatible with the data. This is an absurd implication for responses that cannot have negative values (or are "bounded by" zero). Explicit or implicit error bars that cross zero are especially common for count responses with small means. *If* a researcher plots confidence intervals, these should be computed using a method that avoids absurd implications, such methods include the bootstrap and generalized linear models.
3. **Stars add minimal value**. Many researchers add star symbols to a plot indicating the level of significance of a particular paired comparison. An uncommon, but better, alternative would be to add the actual p-value (as above). Adding a p-value (or stars) does communicate model results, and so adds value to a mean-and-error or box/violin/jitter plot. However, much more value would be added by simply reporting an effects plot or a combined effects-and-response plot.

## Working in R

A reasonable goal of any research project should be a script to generate the final plots entirely within the R environment and not rely on external drawing software to add finishing features. `ggplot2` is one of the major plotting environments in R and the one that seems to have the strongest following, especially among new R users. `ggplot2` has the ability to generate extremely personalized and finished plots. However, creating a plot with multiple layers (bars, lines, error intervals, raw data points, p-values) can often require many hours of googling.

`ggpubr` is an extension to `ggplot2` (it calls ggplot2 functions under the hood) and provides many canned functions for producing the kinds of ggplots that are published in biological journals. With one line of script, a researcher can generate a publishable plot that is as good or better than many published plot.

**Here I show how to add custom (ggplot2) features to a ggpubr plot**

### Unpooled SE bars and confidence intervals
`ggplot2` and `ggpubr` default to unpooled error intervals (standard error bars and confidence intervals).

```{r plots-unpooled, fig.cap="(A) Mean and 1 SE error bar. (B) Mean and 95% CI."}
gg1 <- ggbarplot(data = exp2d,
                 x = "donor", 
                 y = "count", 
                 add = c("mean_se"),
                 fill = "steelblue"
)
gg2 <- ggbarplot(data = exp2d,
                 x = "donor", 
                 y = "count", 
                 add = c("mean_ci"),
                 fill = "steelblue"
)
plot_grid(gg1, gg2, ncol=2, labels="AUTO")
```

### Adding bootstrap intervals

A better CI than an unpooled CI, especially for non-normal data such as counts, is a bootstrap CI. ggplot2 automates this. A stripchart shows the data, which are "de-emphasized" -- in order to emphasize the mean and CI -- by using a lighter shade for the individual points. In order to not *also* de-emphasize the plotted mean, a ggplot2 line plots the mean instead of ggpubr.

```{r}
gg <- ggstripchart(data=exp2d,
                   x="donor", 
                   y="count", 
                   alpha = 0.3
) + 
  stat_summary(fun.data = "mean_cl_boot", 
               geom = "errorbar", 
               width = 0.1) +
  stat_summary(fun.y = "mean", 
               geom = "point", 
               size = 2)


gg
```

### Adding modeled error intervals

Plotting the modeled error intervals "shows the model". `emmeans` is a comprehensive and flexible package for computing modeled standard errors and confidence intervals for all of the statistical models covered in this text.

```{r}
m1 <- glm.nb(count ~ donor, data=exp2d)
emm.m1 <- emmeans(m1, specs="donor", type="response")
effects.m1 <- summary(contrast(emm.m1, method="revpairwise"), infer=c(TRUE, TRUE))

# make emm.m1 a data.table
emm.m1 <- data.table(summary(emm.m1))
# the y column needs to have the same label as the plotted data
setnames(emm.m1, old="response", new="count")
```

#### Modeled error intervals of the effect
```{r, message=FALSE}
(gg1 <- ggdotplot(x="contrast", 
                 y="ratio", 
                 data=effects.m1, 
                 color = "steelblue",
                 fill = "steelblue",
                 size=0.5) +
   
  # add either the SE or CI, contained in effects.m1
  geom_errorbar(aes(x=contrast, ymin=asymp.LCL, ymax=asymp.UCL),
                width=0.15, color="steelblue") +
  ylab("Effect ratio") +
  geom_hline(yintercept=1, linetype = 2) +
  coord_flip() + 
  
  NULL)

```

#### Modeled error intervals of the mean
```{r}
(gg2 <- ggbarplot(x="donor", 
          y="count", 
          data=exp2d,
          add=c("mean", "jitter"),
          color = "darkgray",
          fill = "steelblue",
          size=0.5) +
  ylab("Neutrophil count") +
  
  # emm.m1 contains the SE and 95% CIs. Either could be plotted. Here I plot the CI
  geom_errorbar(data=emm.m1, aes(ymin=asymp.LCL, ymax=asymp.UCL), width=0.1) +
  NULL)

```

Note that the CIs are asymmetric about the mean (and these modeled CIs will never include negative values for count data).

#### Combining effects and response plots

The ggplots are combined using the package `cowplot`

```{r, message=FALSE}
gg_top <- gg1 + scale_y_continuous(position="right")
plot_grid(gg_top, gg2, nrow=2, align = "v", rel_heights = c(1, 1))

```


### Adding p-values

p-values are added to the base ggpubr plot using `stat_compare_means`. The pairs to compare are specified with `comparison =`. The model to compute the p-values is "t.test". **It is important to know what exactly is being computed when analyzing data and reporting results** and "t test" is not sufficient to know this. The t-test could be the classic t-test or a Welch test (which adjusts the standard error to account for heterogenity in variance between groups). In this example, there are multiple tests and the standard error could be the pooled estimate estimated from the linear model, or a pairwise estimate. And, given the multiple comparisons, the p-values could be adjusted or not. These kinds of questions can be checked with a function's help page. `?stat_compare_means` doesn't answer these questions but suggests `compare_means`, which also doesn't answer these questions. The script below has checks to see what p-values the function is returning.

```{r plot-p-values}
pairs_i <- list(c("sox10", "iap_mo"), c("sox10", "gf"), c("sox10", "wt"))
ggbarplot(x="donor", 
          y="count", 
          data=exp2d,
          add=c("mean_se", "jitter"),
          color = "black",
          fill = "steelblue",
          size=0.5) +
  stat_compare_means(method = "t.test", comparisons=pairs_i) +
  ylab("Neutrophil count") +
  NULL

# checks on the p-value
# t-tests using SE pooled over all four groups
check_it <- FALSE
if(check_it==TRUE){
  m1 <- lm(count~donor, data=exp2d)
  m1.emm <- emmeans(m1, specs="donor")
  contrast(m1.emm, method="trt.vs.ctrl", ref=3, adjust="none") # not pooled SE
  
  pairwise.t.test(exp2d$count, exp2d$donor, p.adjust.method="none", pool.sd=FALSE) # this matches
  # compare
  t.test(count~donor, data=exp2d[donor=="wt" | donor=="sox10"]) # matches, this is Welch t
  t.test(count~donor, data=exp2d[donor=="wt" | donor=="sox10"], var.equal=TRUE)
}

```

So the p-values returned by `stat_compare_means(method="t.test")` are computed from independent Welch t-tests.

### Adding custom p-values

What if we want the *p*-values in the plot above to come from a linear model, or a generalized linear model and not from the available tests in the ggpubr package? The function `stat_pvalue_manual` in ggpubr allows this.

Throughout this text, *p*-values are computed using `emmeans::contrast`. To use these *p*-values in a plot, the steps are

1. Fit the model
2. Estimate the means and contrasts using the emmeans package
3. Add a column of formatted p-values to the contrast table
4. Plot the modeled means and error bars
5. Plot the formatted p-values using `stat_pvalue_manual`

Step 3 depends on the model fit in step 1. Here I fit count data using both a linear model, a log-transform, and a generalized linear model to show the how to build a p-value table.

```{r plots-functions}
odd <- function(x) x%%2 != 0
even <- function(x) x%%2 == 0
```

#### Formatted p-values using a linear model
```{r}
m1 <- lm(count ~ donor, data=exp2d)
# estimate the modeled means and CIs
m1.emm <- emmeans(m1, specs="donor")
# estimate the p-values of the contrasts
m1.pairs <- contrast(m1.emm, method="revpairwise") %>%
  summary() %>%
  data.table()
# extract the two groups being compared in each row
groups <- unlist(str_split(m1.pairs$contrast, " - "))
m1.pairs[, group1 := groups[odd(1:length(groups))]]
m1.pairs[, group2 := groups[even(1:length(groups))]]
# create a column of p-values for display.
m1.pairs[, p := pvalString(p.value)]
```

#### Formatted p-values using a model with a log transformed response
If a linear model is fit to data using a transformed response (in this case, the log of the count plus one), the group means are estimated on the transformed scale so need to be backtransformed to the "response" scale using the argument `type = "response"`. With a log transformation, the contrast is now a ratio instead of a difference, and so the script to extract the pair of group names has to be modified from that above.

```{r}
m2 <- lm(log(count+1) ~ donor, data=exp2d)
# estimate the modeled means and CIs on the response scale
m2.emm <- emmeans(m2, specs="donor", type="response")
# estimate the p-values of the contrasts
m2.pairs <- contrast(m2.emm, method="revpairwise") %>%
  summary() %>%
  data.table()
# the contrast column separates with a hypehn
groups <- unlist(str_split(m2.pairs$contrast, " / "))
m2.pairs[, group1 := groups[odd(1:length(groups))]]
m2.pairs[, group2 := groups[even(1:length(groups))]]
# create a column of p-values for display.
m2.pairs[, p := pvalString(p.value)]
```

#### Formatted p-values using a generalized linear model with a log link function
For a generalized linear model that uses a log link, predicted means are estimated on the log scale and need to be backtransformed to the "response" scale using the argument `type = "response"`. The contrast is now a ratio instead of a difference, and the script to extract the pair of group labels has to be modified from that used in the script for the linear model fit.

```{r}
m3 <- glm.nb(count ~ donor, data=exp2d)
m3.emm <- emmeans(m3, specs="donor", type="response")
# estimate the p-values of the contrasts
m3.pairs <- contrast(m3.emm, method="revpairwise") %>%
  summary() %>%
  data.table()
# the contrast column separates with a hypehn
groups <- unlist(str_split(m3.pairs$contrast, " / "))
m3.pairs[, group1 := groups[odd(1:length(groups))]]
m3.pairs[, group2 := groups[even(1:length(groups))]]
# create a column of p-values for display.
m3.pairs[, p := pvalString(p.value)]
```

#### Using the manual p-values in a plot

Here I use the tables from the generalized linear model (m3). The *p*-values are added with `stat_pvalue_manual`. Here, I limit the comparisons to those in rows 4-6. The most manual part of adding manual p-values is setting the position for the brackets using the "position" argument. The values in this argument are the y-coordinates of the brackets. This may take some trial-and-error to position the brackets satisfactorily.

```{r plots-custom-p}
# convert the emm table and change colname "response" to "count"
m3.emm <- data.table(summary(m3.emm))
setnames(m3.emm, old="response", new="count")

gg <- ggbarplot(x="donor", 
          y="count", 
          data=m3.emm, 
          fill = "steelblue") +
  ylab("Count") +
  
  geom_errorbar(aes(x=donor, ymin=asymp.LCL, ymax=asymp.UCL),
                width=0.15) +
  
  geom_jitter(data=exp2d, aes(x=donor, y=count),
             color="black",
             width=0.1, height=0) +
  
  stat_pvalue_manual(m3.pairs[4:6,], # only show sox effects
                           label = "p", 
                           y.position=c(31, 28, 25)) +
  NULL

gg

```

### Plotting two factors

The data are from figure 6d. This solution requires computing either the raw or modeled means and errors and adding these to a base ggpubr plot. Many packages have summary statistics functions for means, standard deviations, and standard errors. This is easily done by simply computing the statistics using data.table functionality.

```{r}
# compute raw statistics
# enclosing the line within parentheses prints the result to the console!
(exp6d.raw <- exp6d[!is.na(count), .(count=mean(count),
                       se=sd(count)/sqrt(.N)),
                   by=.(treatment, strain)]
)
```

Modeled means, standard errors, and confidence limits are conveniently computed using the `emmeans` ("estimated marginal means") function from the emmeans package. 

```{r}

# modeled statsistics
m1 <- glm.nb(count ~ treatment*strain, data=exp6d)
(m1.emm <- data.table(summary(emmeans(m1, specs=c("treatment", "strain"), type="response"))))
# change column "response" to "count" for the ggplot
setnames(m1.emm, old="response", new="count")
```

```{r}

#pairs_i <- list(c("sox10", "iap_mo"), c("sox10", "gf"), c("sox10", "wt"))
pd = position_dodge(0.7)
ggbarplot(x="treatment", 
          y="count",
          data=exp6d,
          add=c("mean"),
          color = "black",
          fill = "strain",
          palette = "jco",
          position = pd,
          size=0.5) +
  #stat_compare_means(method = "t.test", comparisons=pairs_i) +
  ylab("Neutrophil count") +
  # geom_dotplot(aes(fill=strain),
  #              binaxis='y', stackdir='center', position=pd, show.legend=FALSE,
  #              color="grey") +
  geom_point(aes(fill=strain), position=position_jitterdodge(jitter.width=0.2), show.legend=FALSE, alpha=0.5) +
  geom_errorbar(data=m1.emm, aes(x=treatment, ymin=asymp.LCL, ymax=asymp.UCL, group=strain),
                position=pd, width=0.1) +
  NULL


```


### Interaction plot

```{r}
#pairs_i <- list(c("sox10", "iap_mo"), c("sox10", "gf"), c("sox10", "wt"))

pd = position_dodge(0.2)
ggplot(data=m1.emm, aes(x=treatment, y=count, shape=strain, color=strain, group=strain)) +
  geom_point(position=pd, size=3) +
  geom_errorbar(data=m1.emm, aes(x=treatment, ymin=asymp.LCL, ymax=asymp.UCL, group=strain),position=pd, width=0.1) +
  geom_line(position=pd) +
  ylab("Neutrophil count") +
  scale_color_jco() +
  theme_pubr() +
  NULL

```

### Plot components
#### Showing the data

If there are only a few cases per group, there is little reason to summarize the distribution. Instead plot the individual points using a stripchart or a jitter plot

```{r}
# sample 4 points from each group to make it a small n experiment
inc <- exp2d[, .(inc=sample(min(.I):max(.I), 4)), by=donor][, inc]
ggstripchart(x = "donor",
             y = "count",
             alpha = 0.5,
             add = "mean",
             data = exp2d[inc,])
```

With more points, a stripchart can be okay but with too many points the distribution might be obscured. Reasonable alternatives are a box plot, a violin plot, and a dotplot.

```{r, message=FALSE}
gg1 <- ggstripchart(x = "donor",
          y = "count",
          fill="steelblue",
          data = exp2d)

gg2 <- ggboxplot(x = "donor",
          y = "count",
          fill="steelblue",
          data = exp2d)

gg3 <- ggviolin(x = "donor",
          y = "count",
          fill="steelblue",
          data = exp2d)
gg4 <- ggdotplot(x = "donor",
          y = "count",
          fill="steelblue",
          data = exp2d)
plot_grid(gg1, gg2, gg3, gg4, nrow=2)
```

##
